"""
generate_connector.py - Fivetran RSS Connector Generator
=========================================================

This script generates a complete connector.py from discover_results.json

Usage:
    python generate_connector.py

Generates:
    - connector.py (complete, ready to deploy)
    - requirements.txt (if needed)

Author: Bharat Connect Team
Date: 2025-10-25
Version: 4.0 (Full Code Generation)
"""

import json
import os
from datetime import datetime

# ============================================================================
# CONFIGURATION
# ============================================================================

DISCOVERY_FILE = 'discover_results.json'
OUTPUT_FILE = 'connector.py'
REQUIREMENTS_FILE = 'requirements.txt'
MIN_SCORE = 75

# ============================================================================
# CONNECTOR TEMPLATE
# ============================================================================

CONNECTOR_TEMPLATE = '''"""
connector.py - Bharat Connect RSS Connector
============================================
AUTO-GENERATED by generate_connector.py
Generated: {generation_time}

DO NOT EDIT THIS FILE MANUALLY!
Run: python generate_connector.py to regenerate

Features:
- Language tracking (Unicode script detection)
- URL validation + error tracking
- Embedded feed list from discovery agents
- State management for duplicate prevention

Feeds: {feed_count} high-quality feeds (score >= {min_score})
"""

import feedparser
from fivetran_connector_sdk import Connector
from fivetran_connector_sdk import Operations as op
from datetime import datetime, timezone
import time
import hashlib
from typing import Dict, List, Tuple

# ============================================================================
# DISCOVERED FEEDS
# ============================================================================
# Auto-generated from: {discovery_file}
# Total feeds discovered: {total_discovered}
# Quality threshold: score >= {min_score}
# Selected feeds: {feed_count}

DISCOVERED_FEEDS = {feed_list}

# ============================================================================
# TABLE SCHEMAS
# ============================================================================

TABLE_NAME = 'rss_content'
ERROR_TABLE_NAME = 'ingestion_errors'

SCHEMA = [
    {{
        'table': TABLE_NAME,
        'primary_key': ['id'],
        'columns': {{
            'id': 'STRING',
            'title': 'STRING',
            'content': 'STRING',
            'language': 'STRING',
            'source': 'STRING',
            'source_type': 'STRING',
            'published_date': 'UTC_DATETIME',
            'url': 'STRING',
            'rss_feed_url': 'STRING',
            'ingested_at': 'UTC_DATETIME'
        }}
    }},
    {{
        'table': ERROR_TABLE_NAME,
        'primary_key': ['error_id'],
        'columns': {{
            'error_id': 'STRING',
            'error_type': 'STRING',
            'feed_url': 'STRING',
            'source_name': 'STRING',
            'entry_title': 'STRING',
            'reason': 'STRING',
            'timestamp': 'UTC_DATETIME',
            'for_learning': 'BOOLEAN'
        }}
    }}
]

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def detect_language(text: str, source_name: str = '') -> str:
    """Detect language using IndicLID for Hindi/Marathi distinction."""
    if not text:
        return 'en'
    
    # STEP 1: Check source name (most reliable)
    source_lower = source_name.lower()
    lang_keywords = {
        'marathi': 'mr', 'hindi': 'hi', 'tamil': 'ta', 'telugu': 'te',
        'gujarati': 'gu', 'kannada': 'kn', 'malayalam': 'ml',
        'bengali': 'bn', 'punjabi': 'pa', 'english': 'en'
    }
    
    for lang_name, lang_code in lang_keywords.items():
        if lang_name in source_lower:
            return lang_code
    
    # STEP 2: Use statistical language detection for Devanagari text
    text_sample = text[:300]
    
    if any('\\u0900' <= char <= '\\u097F' for char in text_sample):
        # Devanagari script detected - could be Hindi or Marathi
        try:
            from indiclid.inference import langid_lid_predict
            
            detected = langid_lid_predict([text_sample])[0][0]
            
            # IndicLID returns format: "hin_Deva" or "mar_Deva"
            lang_map = {
                'hin_Deva': 'hi',
                'mar_Deva': 'mr',
                'nep_Deva': 'hi',  # Map Nepali to Hindi
            }
            
            result = lang_map.get(detected, 'hi')
            print(f"  IndicLID detected: {detected} -> {result}")
            return result
        except Exception as e:
            print(f"  IndicLID failed: {e}, using lexical fallback")
            return detect_hindi_vs_marathi_lexical(text_sample)
    
    # STEP 3: Other scripts (Unicode range detection)
    if any('\\u0B80' <= char <= '\\u0BFF' for char in text_sample): return 'ta'
    if any('\\u0C00' <= char <= '\\u0C7F' for char in text_sample): return 'te'
    if any('\\u0A80' <= char <= '\\u0AFF' for char in text_sample): return 'gu'
    if any('\\u0C80' <= char <= '\\u0CFF' for char in text_sample): return 'kn'
    if any('\\u0D00' <= char <= '\\u0D7F' for char in text_sample): return 'ml'
    if any('\\u0980' <= char <= '\\u09FF' for char in text_sample): return 'bn'
    if any('\\u0A00' <= char <= '\\u0A7F' for char in text_sample): return 'pa'
    
    return 'en'


def detect_hindi_vs_marathi_lexical(text: str) -> str:
    """Fallback lexical detection for Hindi vs Marathi."""
    
    # Marathi-specific markers
    marathi_markers = [
        'आहे', 'आहेत', 'असतो', 'असते',  # Verb forms
        'मी', 'तू', 'तुम्ही',  # Pronouns
        'मध्ये', 'ला', 'ने',  # Postpositions
        'काय', 'कसे', 'कुठे',  # Question words
        'महाराष्ट्र', 'मुंबई', 'पुणे'  # Place names
    ]
    
    # Hindi-specific markers
    hindi_markers = [
        'है', 'हैं', 'था', 'थी', 'थे',  # Verb forms
        'मैं', 'तुम', 'आप',  # Pronouns
        'में', 'को', 'से',  # Postpositions
        'क्या', 'कैसे', 'कहाँ', 'कब',  # Question words
        'दिल्ली', 'भारत'  # Place names
    ]
    
    marathi_count = sum(1 for m in marathi_markers if m in text)
    hindi_count = sum(1 for m in hindi_markers if m in text)
    
    # Check for Marathi-specific character (ळ)
    marathi_char_bonus = text.count('ळ') * 2
    
    if marathi_count + marathi_char_bonus > hindi_count:
        return 'mr'
    elif hindi_count > 0:
        return 'hi'
    
    return 'hi'

def validate_entry(entry: Dict, source_name: str) -> Tuple[bool, str]:
    """Validate RSS entry - MUST have URL and title."""
    url = entry.get('link') or entry.get('url') or entry.get('guid')
    if not url:
        return False, "missing_url"
    if not entry.get('title'):
        return False, "missing_title"
    return True, ""

def log_error_for_learning(entry: Dict, feed_url: str, source_name: str,
                           error_type: str, reason: str) -> Dict:
    """Create error record for RAG learning feedback."""
    error_id = hashlib.md5(
        f"{{feed_url}}{{entry.get('title', '')}}{{datetime.now().isoformat()}}".encode()
    ).hexdigest()
    
    return {{
        'error_id': error_id,
        'error_type': error_type,
        'feed_url': feed_url,
        'source_name': source_name,
        'entry_title': entry.get('title', 'No title')[:200],
        'reason': reason,
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'for_learning': True
    }}

# ============================================================================
# SCHEMA FUNCTION
# ============================================================================

def schema(configuration: dict):
    return SCHEMA

# ============================================================================
# UPDATE FUNCTION
# ============================================================================

def update(configuration: dict, state: dict):
    """Main sync engine."""
    
    if not DISCOVERED_FEEDS:
        print("No feeds configured")
        return
    
    print(f"Starting RSS sync with {{len(DISCOVERED_FEEDS)}} feeds")
    
    last_sync_timestamp = state.get(TABLE_NAME, {{}}).get('last_sync', 0)
    seen_ids = set(state.get(TABLE_NAME, {{}}).get('seen_ids', []))
    
    print(f"   Last sync: {{datetime.fromtimestamp(last_sync_timestamp, timezone.utc) if last_sync_timestamp else 'Never'}}")
    print(f"   Previously seen: {{len(seen_ids)}} entries")
    
    new_latest_sync_timestamp = last_sync_timestamp
    current_sync_time = datetime.now(timezone.utc)
    new_seen_ids = seen_ids.copy()
    
    total_upserts = 0
    total_errors = 0
    
    for idx, feed_url in enumerate(DISCOVERED_FEEDS, 1):
        try:
            print(f"\\n[{{idx}}/{{len(DISCOVERED_FEEDS)}}] {{feed_url[:60]}}...")
            
            headers = {{
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/xml,text/html,application/xhtml+xml'
            }}
            
            feed = feedparser.parse(feed_url, request_headers=headers)
            
            if hasattr(feed, 'bozo') and feed.bozo:
                print(f"   Warning: {{feed.bozo_exception}}")
            
            source_name = feed.feed.get('title', feed_url.split('/')[-1].split('?')[0])
            print(f"   Found {{len(feed.entries)}} entries")
            
            feed_upserts = 0
            feed_errors = 0
            
            for entry in feed.entries:
                is_valid, error_reason = validate_entry(entry, source_name)
                
                if not is_valid:
                    error_record = log_error_for_learning(
                        entry, feed_url, source_name, error_reason,
                        f"Validation failed: {{error_reason}}"
                    )
                    yield op.upsert(ERROR_TABLE_NAME, error_record)
                    feed_errors += 1
                    continue
                
                entry_url = entry.get('link') or entry.get('url') or entry.get('guid')
                entry_id = entry.get('id') or entry_url
                
                if not entry_id:
                    entry_id = hashlib.md5(
                        f"{{entry.get('title', '')}}{{source_name}}".encode()
                    ).hexdigest()
                
                if entry_id in seen_ids:
                    continue
                
                published_struct = entry.get('published_parsed')
                if published_struct:
                    try:
                        published_dt = datetime.fromtimestamp(
                            time.mktime(published_struct), timezone.utc
                        )
                    except (ValueError, OverflowError):
                        published_dt = current_sync_time
                else:
                    published_dt = current_sync_time
                
                title = entry.get('title', '')
                language = detect_language(title, source_name)
                source_type = 'government' if 'pib' in feed_url.lower() else 'news'
                
                record = {{
                    'id': entry_id,
                    'title': title,
                    'content': entry.get('summary', entry.get('description', '')),
                    'language': language,
                    'source': source_name,
                    'source_type': source_type,
                    'published_date': published_dt.isoformat(),
                    'url': entry_url,
                    'rss_feed_url': feed_url,
                    'ingested_at': current_sync_time.isoformat()
                }}
                
                yield op.upsert(TABLE_NAME, record)
                new_seen_ids.add(entry_id)
                feed_upserts += 1
                total_upserts += 1
                
                if published_dt.timestamp() > new_latest_sync_timestamp:
                    new_latest_sync_timestamp = published_dt.timestamp()
            
            print(f"   Upserted: {{feed_upserts}}, Errors: {{feed_errors}}")
            total_errors += feed_errors
        
        except Exception as e:
            print(f"   Error: {{e}}")
            error_record = log_error_for_learning(
                {{'feed_url': feed_url}}, feed_url, feed_url.split('/')[-1],
                'parsing_error', str(e)
            )
            yield op.upsert(ERROR_TABLE_NAME, error_record)
            total_errors += 1
    
    print(f"\\n{{'='*60}}")
    print(f"RSS Ingestion Complete:")
    print(f"  Upserts: {{total_upserts}}")
    print(f"  Errors: {{total_errors}}")
    print(f"  New entries: {{len(new_seen_ids) - len(seen_ids)}}")
    print(f"{{'='*60}}")
    
    if len(new_seen_ids) > 10000:
        new_seen_ids = set(list(new_seen_ids)[-10000:])
    
    new_state = {{
        TABLE_NAME: {{
            'last_sync': new_latest_sync_timestamp,
            'seen_ids': list(new_seen_ids)
        }}
    }}
    
    yield op.checkpoint(new_state)

# ============================================================================
# REGISTER CONNECTOR
# ============================================================================

connector = Connector(update=update, schema=schema)

if __name__ == '__main__':
    connector.run()
'''

# ============================================================================
# GENERATOR FUNCTIONS
# ============================================================================

def load_discovery_results(json_file=DISCOVERY_FILE):
    """Load discovery results JSON."""
    if not os.path.exists(json_file):
        raise FileNotFoundError(
            f"{json_file} not found!\n"
            f"   Run discovery agents first: python agents/main.py"
        )
    
    with open(json_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def extract_feeds(data, min_score=MIN_SCORE):
    """Extract high-quality feeds."""
    feeds = []
    for feed in data.get('discovered_feeds', []):
        if feed.get('valid', False) and feed.get('score', 0) >= min_score:
            feeds.append(feed['url'])
    return feeds

def format_feed_list(feeds):
    """Format feed list as Python code."""
    if not feeds:
        return '[]'
    
    lines = ['[']
    for feed in feeds:
        lines.append(f'    "{feed}",')
    lines.append(']')
    return '\n'.join(lines)

def generate_connector(discovery_data, feeds):
    """Generate complete connector.py content."""
    
    feed_list_str = format_feed_list(feeds)
    
    return CONNECTOR_TEMPLATE.format(
        generation_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        feed_count=len(feeds),
        min_score=MIN_SCORE,
        discovery_file=DISCOVERY_FILE,
        total_discovered=len(discovery_data.get('discovered_feeds', [])),
        feed_list=feed_list_str
    )

def generate_requirements():
    """Generate requirements.txt with IndicLID."""
    requirements = """feedparser
fivetran-connector-sdk
indiclid
"""
    return requirements

# ============================================================================
# MAIN
# ============================================================================

if __name__ == '__main__':
    print("=" * 70)
    print(" " * 20 + "CONNECTOR GENERATOR")
    print("=" * 70)
    
    try:
        # Step 1: Load discovery results
        print("\nStep 1: Loading discover_results.json...")
        data = load_discovery_results(DISCOVERY_FILE)
        total_discovered = len(data.get('discovered_feeds', []))
        print(f"   Found {total_discovered} total discovered feeds")
        
        # Step 2: Extract high-quality feeds
        print(f"\nStep 2: Extracting feeds (score >= {MIN_SCORE})...")
        feeds = extract_feeds(data, MIN_SCORE)
        print(f"   Selected {len(feeds)} high-quality feeds")
        
        if len(feeds) == 0:
            print(f"\nWarning: No feeds meet quality threshold (score >= {MIN_SCORE})")
            print("   Consider lowering MIN_SCORE in generate_connector.py")
            exit(1)
        
        # Step 3: Generate connector.py
        print(f"\nStep 3: Generating {OUTPUT_FILE}...")
        connector_code = generate_connector(data, feeds)
        
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write(connector_code)
        print(f"   Generated {OUTPUT_FILE} ({len(connector_code)} bytes)")
        
        # Step 4: Generate requirements.txt
        print(f"\nStep 4: Generating {REQUIREMENTS_FILE}...")
        requirements = generate_requirements()
        
        with open(REQUIREMENTS_FILE, 'w', encoding='utf-8') as f:
            f.write(requirements)
        print(f"   Generated {REQUIREMENTS_FILE}")
        
        # Step 5: Preview
        print("\nFeed Preview (first 5):")
        for i, feed in enumerate(feeds[:5], 1):
            print(f"   {i}. {feed[:60]}...")
        
        if len(feeds) > 5:
            print(f"   ... and {len(feeds) - 5} more")
        
        # Step 6: Next steps
        print(f"\n{'=' * 70}")
        print("Connector files generated successfully!")
        print("\nNext steps:")
        print("   1. Test locally:")
        print("      $ fivetran reset")
        print("      $ fivetran debug")
        print("\n   2. Deploy to Fivetran:")
        print("      $ fivetran deploy --api-key <KEY>")
        print("                       --destination bc_bigquery")
        print("                       --connection rss_connector")
        print("=" * 70)
        
    except FileNotFoundError as e:
        print(f"\ Error: {e}")
        exit(1)
    except Exception as e:
        print(f"\nUnexpected error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
